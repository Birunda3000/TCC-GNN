import os
import numpy as np
import matplotlib.pyplot as plt
from collections import Counter
from src.data_loader import DirectWSGLoader
from src.data_converter import DataConverter


def analisar_dados(wsg_file_path):
    """
    Fun√ß√£o para explorar e analisar os dados de um arquivo WSG.

    Args:
        wsg_file_path (str): Caminho para o arquivo .wsg.json
    """
    print("=" * 80)
    print("AN√ÅLISE EXPLORAT√ìRIA DOS DADOS WSG")
    print("=" * 80)
    print(f"Arquivo analisado: {wsg_file_path}")
    print()

    # Carregar os dados
    loader = DirectWSGLoader(file_path=wsg_file_path)
    wsg_obj = loader.load()

    # === METADATA ===
    print("üìä METADADOS:")
    print(f"  Dataset: {wsg_obj.metadata.dataset_name}")
    print(f"  Tipo de features: {wsg_obj.metadata.feature_type}")
    print(f"  N√∫mero total de n√≥s: {wsg_obj.metadata.num_nodes}")
    print(f"  N√∫mero total de arestas: {wsg_obj.metadata.num_edges}")
    print(f"  N√∫mero total de features: {wsg_obj.metadata.num_total_features}")
    print(f"  Grafo direcionado: {'Sim' if wsg_obj.metadata.directed else 'N√£o'}")
    print(f"  Processado em: {wsg_obj.metadata.processed_at}")
    print()

    # === ESTRUTURA DO GRAFO ===
    print("üîó ESTRUTURA DO GRAFO:")

    # An√°lise dos labels (classes)
    y = wsg_obj.graph_structure.y
    labels_validos = [label for label in y if label is not None]
    num_labels_validos = len(labels_validos)
    num_labels_nulos = len(y) - num_labels_validos

    print(f"  Total de n√≥s com labels: {num_labels_validos}")
    print(f"  Total de n√≥s sem labels: {num_labels_nulos}")

    if labels_validos:
        classes_unicas = sorted(set(labels_validos))
        num_classes = len(classes_unicas)
        print(f"  N√∫mero de classes: {num_classes}")
        print(f"  Classes encontradas: {classes_unicas}")

        # Distribui√ß√£o das classes
        contagem_classes = Counter(labels_validos)
        print("  Distribui√ß√£o das classes:")
        for classe, count in sorted(contagem_classes.items()):
            porcentagem = (count / num_labels_validos) * 100
            print(f"    Classe {classe}: {count} amostras ({porcentagem:.2f}%)")

        # Estat√≠sticas de balanceamento
        valores = list(contagem_classes.values())
        media = np.mean(valores)
        desvio = np.std(valores)
        minimo = min(valores)
        maximo = max(valores)
        print(f"  Estat√≠sticas de balanceamento:")
        print(f"    M√©dia por classe: {media:.1f}")
        print(f"    Desvio padr√£o: {desvio:.1f}")
        print(f"    Classe menor: {minimo} amostras")
        print(f"    Classe maior: {maximo} amostras")

        # Plot da distribui√ß√£o (opcional)
        plt.figure(figsize=(10, 6))
        plt.bar(contagem_classes.keys(), contagem_classes.values())
        plt.xlabel("Classe")
        plt.ylabel("N√∫mero de Amostras")
        plt.title("Distribui√ß√£o das Classes")
        plt.xticks(classes_unicas)
        plt.grid(True, alpha=0.3)
        plt.savefig("distribuicao_classes.png", dpi=300, bbox_inches="tight")
        plt.show()
        print("  üìà Gr√°fico salvo como 'distribuicao_classes.png'")
    else:
        print("  ‚ö†Ô∏è  Nenhum label v√°lido encontrado!")

    print()

    # An√°lise das arestas
    edge_index = wsg_obj.graph_structure.edge_index
    if isinstance(edge_index, list) and len(edge_index) == 2:
        sources, targets = edge_index
        print(f"  Arestas: {len(sources)} conex√µes")

        # Calcular graus dos n√≥s
        graus = Counter(sources + targets)
        graus_entrada = Counter(targets)
        graus_saida = Counter(sources)

        print(f"  N√≥s com conex√µes: {len(graus)}")
        print(f"  Grau m√©dio: {np.mean(list(graus.values())):.2f}")
        print(f"  Grau m√°ximo: {max(graus.values())}")
        print(f"  Grau m√≠nimo: {min(graus.values())}")

        # Plot da distribui√ß√£o de graus (opcional)
        plt.figure(figsize=(12, 5))

        plt.subplot(1, 2, 1)
        plt.hist(list(graus.values()), bins=50, alpha=0.7, edgecolor="black")
        plt.xlabel("Grau")
        plt.ylabel("N√∫mero de N√≥s")
        plt.title("Distribui√ß√£o de Graus (Total)")
        plt.yscale("log")
        plt.grid(True, alpha=0.3)

        plt.subplot(1, 2, 2)
        if wsg_obj.metadata.directed:
            plt.hist(
                list(graus_entrada.values()),
                bins=50,
                alpha=0.7,
                label="Entrada",
                edgecolor="black",
            )
            plt.hist(
                list(graus_saida.values()),
                bins=50,
                alpha=0.7,
                label="Sa√≠da",
                edgecolor="black",
            )
            plt.legend()
            plt.title("Distribui√ß√£o de Graus (Direcionado)")
        else:
            plt.hist(list(graus.values()), bins=50, alpha=0.7, edgecolor="black")
            plt.title("Distribui√ß√£o de Graus (N√£o Direcionado)")
        plt.xlabel("Grau")
        plt.ylabel("N√∫mero de N√≥s")
        plt.yscale("log")
        plt.grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig("distribuicao_graus.png", dpi=300, bbox_inches="tight")
        plt.show()
        print("  üìà Gr√°fico de graus salvo como 'distribuicao_graus.png'")
    else:
        print("  ‚ö†Ô∏è  Formato de edge_index inv√°lido!")

    print()

    # === FEATURES DOS N√ìS ===
    print("üîç FEATURES DOS N√ìS:")

    node_features = wsg_obj.node_features
    feature_type = wsg_obj.metadata.feature_type

    print(f"  Tipo de features: {feature_type}")
    print(f"  N√≥s com features: {len(node_features)}")

    if feature_type == "dense_continuous":
        # Para embeddings densos
        pesos_todos = []
        for node_id, feature in node_features.items():
            pesos_todos.extend(feature.weights)

        if pesos_todos:
            pesos_array = np.array(pesos_todos)
            print(f"  Dimens√£o dos embeddings: {len(feature.weights)}")
            print(f"  Total de valores: {len(pesos_array)}")
            print(f"  M√©dia dos pesos: {np.mean(pesos_array):.4f}")
            print(f"  Desvio padr√£o: {np.std(pesos_array):.4f}")
            print(f"  Valor m√≠nimo: {np.min(pesos_array):.4f}")
            print(f"  Valor m√°ximo: {np.max(pesos_array):.4f}")

            # Plot da distribui√ß√£o dos valores dos embeddings
            plt.figure(figsize=(10, 6))
            plt.hist(pesos_array, bins=100, alpha=0.7, edgecolor="black")
            plt.xlabel("Valor do Embedding")
            plt.ylabel("Frequ√™ncia")
            plt.title("Distribui√ß√£o dos Valores dos Embeddings")
            plt.grid(True, alpha=0.3)
            plt.savefig("distribuicao_embeddings.png", dpi=300, bbox_inches="tight")
            plt.show()
            print("  üìà Histograma salvo como 'distribuicao_embeddings.png'")

    elif feature_type == "sparse_binary":
        # Para features esparsas
        indices_todos = []
        for node_id, feature in node_features.items():
            indices_todos.extend(feature.indices)

        indices_unicos = set(indices_todos)
        print(f"  Features distintas usadas: {len(indices_unicos)}")
        print(
            f"  Densidade m√©dia por n√≥: {len(indices_todos) / len(node_features):.2f}"
        )

        # Distribui√ß√£o do n√∫mero de features por n√≥
        num_features_por_no = [
            len(feature.indices) for feature in node_features.values()
        ]
        print(f"  M√©dia de features por n√≥: {np.mean(num_features_por_no):.2f}")
        print(f"  M√°ximo de features por n√≥: {max(num_features_por_no)}")
        print(f"  M√≠nimo de features por n√≥: {min(num_features_por_no)}")

    print()

    # === CONVERS√ÉO PARA PYG E AN√ÅLISE ADICIONAL ===
    print("üîÑ CONVERS√ÉO PARA PYTORCH GEOMETRIC:")
    try:
        pyg_data = DataConverter.to_pyg_data(wsg_obj)
        print("  ‚úÖ Convers√£o bem-sucedida!")
        print(f"  Shape dos dados X: {pyg_data.x.shape}")
        print(f"  Shape do edge_index: {pyg_data.edge_index.shape}")
        print(f"  Shape dos labels y: {pyg_data.y.shape}")
        print(f"  N√≥s de treino: {pyg_data.train_mask.sum().item()}")
        print(f"  N√≥s de teste: {pyg_data.test_mask.sum().item()}")
    except Exception as e:
        print(f"  ‚ùå Erro na convers√£o: {e}")

    print()
    print("=" * 80)
    print("AN√ÅLISE CONCLU√çDA!")
    print("=" * 80)


if __name__ == "__main__":
    # Caminho padr√£o - altere conforme necess√°rio
    wsg_file_path = "data/output/EMBEDDING_RUNS/musae-github__loss_0_9483__emb_dim_32__01-10-2025_14-58-11/musae-github_embeddings.wsg.json"

    # Verifica se o arquivo existe
    if not os.path.exists(wsg_file_path):
        print(f"‚ùå Arquivo n√£o encontrado: {wsg_file_path}")
        print("Por favor, ajuste o caminho do arquivo WSG.")
    else:
        analisar_dados(wsg_file_path)
