# TCC-GNN: Framework para Gera√ß√£o e An√°lise de Embeddings de Grafos

Este reposit√≥rio cont√©m o c√≥digo-fonte de um framework desenvolvido para experimenta√ß√£o com Redes Neurais de Grafos (GNNs). O foco principal √© a gera√ß√£o de *node embeddings* (representa√ß√µes vetoriais de n√≥s) de forma auto-supervisionada usando um *Variational Graph Autoencoder* (VGAE) e a subsequente avalia√ß√£o da qualidade desses embeddings em tarefas de classifica√ß√£o de n√≥s.

O projeto √© constru√≠do com √™nfase em modularidade, reprodutibilidade e um pipeline de dados bem definido, utilizando um formato de dados customizado chamado **Weighted Sparse Graph (WSG)**.

## Tabela de Conte√∫dos

1.  [Principais Funcionalidades](https://www.google.com/search?q=%23principais-funcionalidades)
2.  [Como Come√ßar](https://www.google.com/search?q=%23-como-come%C3%A7ar)
      * [Pr√©-requisitos](https://www.google.com/search?q=%23pr%C3%A9-requisitos)
      * [Configura√ß√£o do Ambiente](https://www.google.com/search?q=%23configura%C3%A7%C3%A3o-do-ambiente)
3.  [Fluxos de Trabalho](https://www.google.com/search?q=%23-fluxos-de-trabalho)
      * [Fluxo 1: Gera√ß√£o de Embeddings](https://www.google.com/search?q=%23fluxo-1-gera%C3%A7%C3%A3o-de-embeddings)
      * [Fluxo 2: Avalia√ß√£o dos Embeddings](https://www.google.com/search?q=%23fluxo-2-avalia%C3%A7%C3%A3o-dos-embeddings)
      * [Exemplo de Experimento Completo](https://www.google.com/search?q=%23exemplo-de-experimento-completo)
4.  [Estrutura do Projeto](https://www.google.com/search?q=%23estrutura-do-projeto)
5.  [Extens√£o e Personaliza√ß√£o](https://www.google.com/search?q=%23-extens%C3%A3o-e-personaliza%C3%A7%C3%A3o)
      * [Adicionando Novos Datasets](https://www.google.com/search?q=%23adicionando-novos-datasets)
      * [Adicionando Novos Classificadores](https://www.google.com/search?q=%23adicionando-novos-classificadores)
6.  [Nota sobre Anonimiza√ß√£o](https://www.google.com/search?q=%23-nota-sobre-anonimiza%C3%A7%C3%A3o)
7.  [Contribui√ß√µes](https://www.google.com/search?q=%23contribui%C3%A7%C3%B5es)
8.  [Licen√ßa](https://www.google.com/search?q=%23licen%C3%A7a)
9.  [Contato](https://www.google.com/search?q=%23contato)

## Principais Funcionalidades

  - **Formato de Dados Padronizado (WSG):** Define uma especifica√ß√£o (`.wsg.json`) para representar grafos de maneira universal, desacoplando a prepara√ß√£o dos dados da modelagem.
  - **Ambiente Reproduz√≠vel com Docker:** Configura√ß√£o completa para `dev containers` do VS Code, com suporte para ambientes **CPU** e **GPU (NVIDIA)**, garantindo que o projeto funcione de forma consistente em diferentes m√°quinas.
  - **Pipeline Modular:**
    1.  **Carregamento de Dados:** Converte datasets brutos (ex: Musae-Github) para o formato WSG.
    2.  **Gera√ß√£o de Embeddings:** Treina um modelo VGAE para aprender representa√ß√µes de n√≥s e salva os embeddings resultantes em um novo arquivo WSG.
    3.  **Avalia√ß√£o em Tarefas Downstream:** Utiliza os embeddings gerados para treinar e avaliar modelos de classifica√ß√£o (MLP, Regress√£o Log√≠stica, etc.).
  - **Gera√ß√£o de Embeddings com VGAE:** Implementa√ß√£o de um *Variational Graph Autoencoder* em PyTorch Geometric para aprender embeddings de n√≥s de forma auto-supervisionada.
  - **Gerenciamento de Experimentos:** Salva automaticamente os resultados de cada execu√ß√£o (modelo treinado, embeddings, logs e m√©tricas) em diret√≥rios nomeados de forma descritiva.
  - **Anonimiza√ß√£o de Features:** Inclui um script para aplicar privacidade diferencial (mecanismo de Laplace) √†s features dos n√≥s e avaliar o impacto na utilidade dos dados para tarefas de classifica√ß√£o.

## üöÄ Como Come√ßar

Este projeto foi projetado para ser executado dentro de um ambiente de desenvolvimento em cont√™iner, o que simplifica a configura√ß√£o.

### Pr√©-requisitos

  - [Docker](https://www.docker.com/get-started)
  - [Visual Studio Code](https://code.visualstudio.com/)
  - Extens√£o [Dev Containers](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers) para o VS Code.

### Configura√ß√£o do Ambiente

1.  **Clone o reposit√≥rio:**

    ```bash
    git clone <URL_DO_SEU_REPOSITORIO>
    cd gnn_tcc
    ```

2.  **Escolha o ambiente (CPU ou GPU):**

      - Abra o arquivo `.devcontainer/devcontainer.json`.
      - Por padr√£o, ele est√° configurado para usar o ambiente de CPU:
        ```json
        "dockerComposeFile": "docker-compose.cpu.yml"
        ```
      - Se voc√™ possui uma GPU NVIDIA e os drivers corretos instalados, pode mudar para o ambiente de GPU, comentando uma linha e descomentando a outra:
        ```json
        // "dockerComposeFile": "docker-compose.cpu.yml",
        "dockerComposeFile": "docker-compose.gpu.yml"
        ```

3.  **Abra o projeto no Dev Container:**

      - No VS Code, pressione `F1` para abrir a paleta de comandos.
      - Digite e selecione **"Dev Containers: Reopen in Container"**.
      - O VS Code ir√° construir a imagem Docker e iniciar o cont√™iner. Este processo pode levar alguns minutos na primeira vez.

## ‚öôÔ∏è Fluxos de Trabalho

O framework oferece dois fluxos principais de trabalho, implementados como scripts separados.

### Fluxo 1: Gera√ß√£o de Embeddings

Este fluxo treina um modelo VGAE em um dataset de grafo para gerar embeddings densos que capturam tanto as caracter√≠sticas dos n√≥s quanto a estrutura da rede.

#### **Configura√ß√£o**

1.  **Ajuste os par√¢metros no arquivo `src/config.py`:**
      * `DATASET_NAME`: Define o dataset a ser usado (ex: "musae-github", "cora").
      * `EMBEDDING_DIM`: Dimens√£o do embedding inicial das features.
      * `HIDDEN_DIM`: Dimens√£o da camada oculta do GNN.
      * `OUT_EMBEDDING_DIM`: Dimens√£o final dos embeddings gerados.
      * `EPOCHS`: N√∫mero de √©pocas de treinamento.
      * `LEARNING_RATE`: Taxa de aprendizado para o otimizador.

#### **Execu√ß√£o**

```bash
python run_embedding_generation.py
```

#### **O que acontece:**

1.  **Carregamento dos dados:** O script carrega o dataset especificado em `DATASET_NAME`.
2.  **Convers√£o de formato:** Os dados s√£o convertidos para o formato do PyTorch Geometric.
3.  **Treinamento do modelo:** Um VGAE √© treinado para reconstruir as arestas do grafo.
4.  **Extra√ß√£o de embeddings:** Os n√≥s s√£o codificados no espa√ßo latente do autoencoder.
5.  **Salvamento dos resultados:** Os embeddings, o modelo treinado e um relat√≥rio s√£o salvos em uma pasta em `data/output/EMBEDDING_RUNS/`, seguindo o padr√£o:
    ```
    [dataset]__loss_[valor]__emb_dim_[dimens√£o]__[timestamp]/
    ‚îú‚îÄ‚îÄ [dataset]_embeddings.wsg.json  # Embeddings no formato WSG
    ‚îú‚îÄ‚îÄ vgae_model.pt                  # Modelo treinado
    ‚îî‚îÄ‚îÄ run_summary.txt                # Relat√≥rio com m√©tricas e tempos
    ```

### Fluxo 2: Avalia√ß√£o dos Embeddings

Este fluxo avalia a qualidade dos embeddings gerados usando m√∫ltiplos classificadores e m√©tricas.

#### **Configura√ß√£o**

1.  **Especifique o arquivo de embeddings a ser avaliado:**
      * Abra o script `run_feature_classification.py`.
      * Edite a vari√°vel `wsg_file_path` para apontar para o arquivo `.wsg.json` que voc√™ deseja avaliar (gerado no fluxo anterior).

#### **Execu√ß√£o**

```bash
python run_feature_classification.py
```

#### **O que acontece:**

1.  **Carregamento dos embeddings:** O arquivo WSG especificado √© carregado.
2.  **Treinamento de classificadores:** Quatro modelos s√£o treinados e avaliados:
      * **LogisticRegression:** Testa a separabilidade linear das classes.
      * **KNeighborsClassifier (KNN):** Testa a coes√£o local dos embeddings.
      * **RandomForestClassifier:** Testa rela√ß√µes n√£o-lineares complexas.
      * **MLPClassifier:** Testa a capacidade de redes neurais de utilizar os embeddings.
3.  **Gera√ß√£o de Relat√≥rios:** Os resultados s√£o compilados, exibidos no console e salvos em um arquivo.

#### **Sa√≠da:**

1.  **Relat√≥rio no console:** Uma tabela comparativa √© exibida no terminal:
    ```
    RELAT√ìRIO DE COMPARA√á√ÉO FINAL
    -------------------------------------------------------------
    Fonte dos Dados: musae-github_embeddings.wsg.json
    Tipo de Feature: dense_continuous
    -------------------------------------------------------------
    Modelo                    | Acur√°cia     | F1-Score     | Tempo (s) 
    =================================================================
    LogisticRegression        | 0.8491       | 0.8398       | 0.43      
    KNeighborsClassifier      | 0.8354       | 0.8308       | 0.01      
    RandomForestClassifier    | 0.8481       | 0.8419       | 13.00     
    MLPClassifier             | 0.8534       | 0.8476       | 23.41     
    ```
2.  **Relat√≥rio detalhado em JSON:** Um arquivo JSON com os resultados √© salvo em `data/output/CLASSIFICATION_RUNS/`.

### Exemplo de Experimento Completo

Para uma avalia√ß√£o completa, o processo ideal √©:

1.  **Gere embeddings com diferentes dimens√µes:**

      * Altere `OUT_EMBEDDING_DIM` em `src/config.py` (ex: 16, 32, 64, 128).
      * Execute `run_embedding_generation.py` para cada configura√ß√£o.

2.  **Avalie cada conjunto de embeddings:**

      * Para cada arquivo de embedding gerado, atualize o `wsg_file_path` em `run_feature_classification.py`.
      * Execute o script de classifica√ß√£o.

3.  **Compare os resultados:**

      * Analise os relat√≥rios para encontrar o melhor equil√≠brio entre **dimensionalidade**, **acur√°cia** e **tempo de treinamento**.

## Estrutura do Projeto

```
/app/gnn_tcc/
‚îú‚îÄ‚îÄ .devcontainer/         # Configura√ß√µes do Docker e VS Code Dev Container (CPU/GPU)
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ datasets/          # Datasets brutos (ex: musae-github)
‚îÇ   ‚îî‚îÄ‚îÄ output/            # Diret√≥rio para salvar os resultados dos experimentos
‚îú‚îÄ‚îÄ src/                   # C√≥digo-fonte principal do projeto
‚îÇ   ‚îú‚îÄ‚îÄ anon.py            # Script para anonimiza√ß√£o de dados
‚îÇ   ‚îú‚îÄ‚îÄ classifiers.py     # Defini√ß√£o de modelos de classifica√ß√£o (MLP, GCN)
‚îÇ   ‚îú‚îÄ‚îÄ config.py          # Configura√ß√µes centralizadas do projeto
‚îÇ   ‚îú‚îÄ‚îÄ data_converter.py  # Conversor do formato WSG para PyTorch Geometric
‚îÇ   ‚îú‚îÄ‚îÄ data_format_definition.py # Defini√ß√£o Pydantic do formato WSG
‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py     # Loaders para carregar datasets para o formato WSG
‚îÇ   ‚îú‚îÄ‚îÄ directory_manager.py # Gerenciador de diret√≥rios de sa√≠da
‚îÇ   ‚îú‚îÄ‚îÄ model.py           # Defini√ß√£o do modelo VGAE
‚îÇ   ‚îú‚îÄ‚îÄ train.py           # L√≥gica de treinamento do VGAE
‚îÇ   ‚îî‚îÄ‚îÄ train_loop.py      # L√≥gica de treinamento para os classificadores
‚îú‚îÄ‚îÄ requirements.txt       # Depend√™ncias Python
‚îú‚îÄ‚îÄ run_embedding_generation.py # Script principal para gerar embeddings
‚îî‚îÄ‚îÄ run_feature_classification.py # Script principal para avaliar classificadores
```

## üß© Extens√£o e Personaliza√ß√£o

### Adicionando Novos Datasets

1.  Crie uma nova classe loader em `src/data_loader.py`:
    ```python
    class NewDatasetLoader(BaseDatasetLoader):
        def load(self) -> WSG:
            # Implementa√ß√£o da l√≥gica de carregamento
            ...
    ```
2.  Registre-o na fun√ß√£o `get_loader` no mesmo arquivo:
    ```python
    def get_loader(dataset_name: str) -> BaseDatasetLoader:
        loaders = {
            # ...outros loaders
            "new-dataset": NewDatasetLoader(),
        }
    ```

### Adicionando Novos Classificadores

1.  **Modelos scikit-learn:** Basta adicionar uma nova inst√¢ncia √† lista `models_to_run` em `run_feature_classification.py`:
    ```python
    models_to_run = [
        # ...outros modelos
        SklearnClassifier(config, model_class=NovoClassificador, **params),
    ]
    ```
2.  **Modelos PyTorch:** Crie uma nova classe que herde de `PyTorchClassifier` em `src/classifiers.py` e implemente sua arquitetura.

## üìù Nota sobre Anonimiza√ß√£o

O arquivo `src/anon.py` cont√©m uma funcionalidade experimental para aplicar privacidade diferencial (mecanismo de Laplace) aos embeddings. Ele permite an√°lises sobre o trade-off entre privacidade e utilidade, mas n√£o est√° integrado ao fluxo principal de trabalho.

## Contribui√ß√µes

Contribui√ß√µes s√£o bem-vindas\! Sinta-se √† vontade para abrir *issues* ou enviar *pull requests*.
